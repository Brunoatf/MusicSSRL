{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-supervised Music Representation Learning for Recommendation Systems\n",
    "\n",
    "- Andreas Cisi Ramos (246932)\n",
    "- Bruno Amaral Teixeira de Freitas (246983)\n",
    "\n",
    "# Project Introduction\n",
    "\n",
    "This project aims to develop a music recommendation system based on self-supervised learning, capable of generating latent representations (or *embeddings*) directly from music audio files. Unlike traditional methods that rely on labeled data or explicit metadata, self-supervised learning allows the model to autonomously extract acoustic and contextual features, capturing musical aspects that might otherwise go unnoticed.\n",
    "\n",
    "Through these representations, the system can more accurately compare songs, highlighting similarities that do not solely depend on labels like genre or artist but are based on sound similarity and usage context. This approach is expected to improve the quality of recommendations, making them more personalized and aligned with users' implicit preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Structure\n",
    "\n",
    "This project will be divided into several stages to organize and facilitate the development of the system:\n",
    "\n",
    "- **Data reading and visualization**, to understand the main characteristics of the music dataset used and prepare the audio data for the following stages.\n",
    "- **Model creation**, where we will implement self-supervised learning techniques to generate the latent representations (*embeddings*) of the songs.\n",
    "- **Embedding visualization and comparison**, where we will use dimensionality reduction methods, such as t-SNE or PCA, to visualize the distribution of songs in vector space. This stage will allow us to observe the similarities and differences among the generated embeddings and verify whether similar songs are indeed close in this space.\n",
    "- **Testing and evaluation**, where we will analyze the quality of the recommendations generated and validate the system's ability to identify sonic and contextual similarities.\n",
    "- **Qualitative analysis of results**, discussing the strengths and limitations of the developed model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Data Reading and Visualization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 - Model Creation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3 - Embedding Visualization and Comparison**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4 - Testing and Evaluation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5 - Qualitative Analysis of Results**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
